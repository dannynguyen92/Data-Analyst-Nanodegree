# [Udacity Data Analyst Nanodegree](https://www.udacity.com/course/data-analyst-nanodegree--nd002)

> Discover insights from data through the use of Python (Pandas, matplotlib, Seaborn and SQL)

## Skills Acquired (Summary)
- Exploratory data analysis (EDA)
- Data Wrangling
- A/B Testing
- Data collection by using web scrapping (BeautifulSoup) and APIs
- Communicate findings using data visualization

## Certificate

[Data Analyst Nanodegree](https://graduation.udacity.com/confirm/7KUNLRQD)

## Project Overview
### P1: Explore Weather Trends

The first chapter was an introduction to the following projects of the Data Analyst Nanodegree.

First chapter project was about weather trends - it required to apply (atleast) the following steps:
* Extract data from a database using a SQL query
* Calculate a moving average
* Create a line chart 

This project is to provide weather trend analysis between Sydney and the world using their annual average temperature from 1841 to 2013

**Key findings**:
- Sydney temperature is consistently higher than the global temperature
- Both Sydney and global temperature have an upward trend in the change of temperature across the period
- The rise in global average temperature is positively correlated to Sydney’s temperature

### P2: Investiagte TMDB Movie Data

This chapter was all about the data analysis process as whole. From gathering to cleaning, assessing and wrangling to exploring and visualizing the data over the programming workflow and communication was everything included. 

This project included therefore all steps of the typical data analysis process. This includes:
- posing questions
- gather, wrangle and clean data 
- communicate answers to the questions 
- assited through visualizations and statistics. 

Out of the project:

> This project will examine datasets for 10,000 movies in IMDB database. My goal is to explore the followings:

- What genres are the most popular among the movies made?
- Which genres are most popular from year to year?
- What kinds of properties are associated with movies that have high revenues?


### P3: Analyze A/B Test Results

Following chapter was filled with *a lot* of information. We talked about: Data Types, Notation, Mean, Standard Deviation, Correlation, Data Shapes, Outliers, Bias, Dangers, Probability and Bayes, Distributions, Central Limit Theorem, Bootstrapping, Confidence Intervals, Hypothesis Testing, A/B Tests, Linear Regression, Logistic Regression and more.. 

### P4: Gather, Clean and Analyze Twitter Data (WeRateDogs™ (@dog_rates))

This chapter was a deep dive into the data wrangling part of the data analysis process. We learned about the difference between messy and dirty data, how tidy data should look like, about the assessing, defining, cleaning and testing process, etc. Moreover, we talked about many different file types and different methods of gathering data. 

In this project we had to deal with the reality of dirty and messy data (again). We gathered data from different sources (for example the Twitter API), identified issues with the dataset in terms of tidiness and quality. Afterwards we had to solve these problems while documenting each step. The end of the project was then focused on the exploration of the data.


### P5: Communicate Data Findings

The final chapter was focused on proper visualization of data. We learned about chart junk, uni-, bi- and multivariate visualization, use of color, data/ink ratio, the lief factor, other encodings.

The task of the final project was to analyze and visualize real-world data. I chose the Ford GoBike dataset.

